{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGi9355KB0ML"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install keras-tuner\n",
        "!pip install backtesting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import datetime as dt\n",
        "import yfinance as yf\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dense, Dropout\n",
        "from backtesting import Backtest, Strategy\n",
        "from backtesting.lib import crossover\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras_tuner import RandomSearch\n"
      ],
      "metadata": {
        "id": "oNpNg3KNCIos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_start_date = dt.datetime(2022, 1, 1)\n",
        "train_end_date = dt.datetime(2023, 12, 31)\n",
        "\n",
        "test_start_date = dt.datetime(2024, 1, 1)\n",
        "test_end_date = dt.datetime(2024, 6, 5)\n",
        "\n",
        "train_data = yf.download(\"AAPL\", start=train_start_date, end=train_end_date)\n",
        "test_data = yf.download(\"AAPL\", start=test_start_date, end=test_end_date)\n",
        "\n",
        "train_data = train_data.iloc[:, :1]\n",
        "test_data = test_data.iloc[:, :1]\n",
        "\n",
        "\n",
        "dataset_train = train_data.Open.values\n",
        "dataset_test = test_data.Open.values\n",
        "\n",
        "\n",
        "dataset_train = np.reshape(dataset_train, (-1, 1))\n",
        "dataset_test = np.reshape(dataset_test, (-1, 1))\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_train = scaler.fit_transform(dataset_train)\n",
        "scaled_test = scaler.transform(dataset_test)\n",
        "\n",
        "\n",
        "X_train = np.array([scaled_train[i-1:i] for i in range(1, len(scaled_train))])\n",
        "y_train = scaled_train[1:]\n",
        "\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
        "\n",
        "\n",
        "regressor = Sequential()\n",
        "\n",
        "regressor.add(SimpleRNN(units=50, activation=\"tanh\", return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(SimpleRNN(units=50, activation=\"tanh\", return_sequences=True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(SimpleRNN(units=50, activation=\"tanh\", return_sequences=True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(SimpleRNN(units=50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "regressor.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "regressor.compile(optimizer='adam', loss=\"mean_squared_error\")\n",
        "\n",
        "\n",
        "regressor.fit(X_train, y_train, epochs=20, batch_size=2)\n",
        "\n",
        "class RNNForecastStrategy(Strategy):\n",
        "    def init(self):\n",
        "        self.signal = self.I(self.predict_prices, self.data.Open)\n",
        "\n",
        "    def predict_prices(self, data):\n",
        "\n",
        "        data = np.array(data).reshape(-1, 1)\n",
        "\n",
        "\n",
        "        scaled_data = scaler.transform(data)\n",
        "        X = np.array([scaled_data[i-1:i] for i in range(1, len(scaled_data))])\n",
        "        X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "\n",
        "        predicted = regressor.predict(X)\n",
        "        predicted = scaler.inverse_transform(predicted)\n",
        "\n",
        "\n",
        "        predicted_padded = np.zeros(len(data))\n",
        "        predicted_padded[1:] = predicted.flatten()\n",
        "        predicted_padded[0] = data[0]\n",
        "\n",
        "        return predicted_padded\n",
        "\n",
        "    def next(self):\n",
        "        if crossover(self.signal, self.data.Close):\n",
        "            self.buy()\n",
        "        elif crossover(self.data.Close, self.signal):\n",
        "            self.sell()\n",
        "\n",
        "data_for_backtest = yf.download(\"AAPL\", start=test_start_date, end=test_end_date)\n",
        "bt = Backtest(data_for_backtest, RNNForecastStrategy, cash=10000, commission=.002)\n",
        "stats = bt.run()\n",
        "bt.plot()\n"
      ],
      "metadata": {
        "id": "qnoENPwXCNln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_for_backtest = yf.download(\"AAPL\", start=test_start_date, end=test_end_date)\n",
        "bt = Backtest(data_for_backtest, RNNForecastStrategy, cash=10000, commission=.002)\n",
        "stats = bt.run()\n",
        "bt.plot()"
      ],
      "metadata": {
        "id": "QP4cZ2LqCUU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras_tuner import RandomSearch, HyperParameters\n",
        "from backtesting import Backtest, Strategy\n",
        "from backtesting.lib import crossover\n",
        "\n",
        "train_start_date = dt.datetime(2023, 1, 1)\n",
        "train_end_date = dt.datetime(2023, 12, 31)\n",
        "test_start_date = dt.datetime(2024, 1, 1)\n",
        "test_end_date = dt.datetime(2024, 6, 5)\n",
        "\n",
        "train_data = yf.download(\"AAPL\", start=train_start_date, end=train_end_date)\n",
        "test_data = yf.download(\"AAPL\", start=test_start_date, end=test_end_date)\n",
        "\n",
        "dataset_train = train_data['Open'].values.reshape(-1, 1)\n",
        "dataset_test = test_data['Open'].values.reshape(-1, 1)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_train = scaler.fit_transform(dataset_train)\n",
        "scaled_test = scaler.transform(dataset_test)\n",
        "\n",
        "def create_sequences(data, seq_length):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(seq_length, len(data)):\n",
        "        X.append(data[i-seq_length:i])\n",
        "        y.append(data[i])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 60\n",
        "X_train, y_train = create_sequences(scaled_train, seq_length)\n",
        "X_test, y_test = create_sequences(scaled_test, seq_length)\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Int('units', min_value=50, max_value=200, step=50),\n",
        "                   return_sequences=True,\n",
        "                   input_shape=(X_train.shape[1], 1)))\n",
        "    model.add(Dropout(hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    for i in range(hp.Int('num_layers', 1, 4)):\n",
        "        model.add(LSTM(units=hp.Int(f'units_{i}', min_value=50, max_value=200, step=50), return_sequences=True))\n",
        "        model.add(Dropout(hp.Float(f'dropout_{i}', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(LSTM(units=hp.Int('units_last', min_value=50, max_value=200, step=50)))\n",
        "    model.add(Dropout(hp.Float('dropout_last', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=2,\n",
        "    directory='lstm_hyperparam_tuning',\n",
        "    project_name='AAPL_LSTM'\n",
        ")\n",
        "\n",
        "\n",
        "X_train_partial = X_train[:int(0.8 * len(X_train))]\n",
        "y_train_partial = y_train[:int(0.8 * len(y_train))]\n",
        "X_val = X_train[int(0.8 * len(X_train)):]\n",
        "y_val = y_train[int(0.8 * len(y_train)):]\n",
        "\n",
        "\n",
        "tuner.search(X_train_partial, y_train_partial, epochs=10, validation_data=(X_val, y_val), batch_size=32)\n",
        "\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The optimal number of units in the first LSTM layer is {best_hps.get('units')},\n",
        "the optimal dropout rate is {best_hps.get('dropout')},\n",
        "the optimal number of layers is {best_hps.get('num_layers')},\n",
        "and the optimal learning rate is {best_hps.get('learning_rate')}.\n",
        "\"\"\")\n",
        "\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "class LSTMForecastStrategy(Strategy):\n",
        "    def init(self):\n",
        "        self.signal = self.I(self.predict_prices, self.data.Open)\n",
        "\n",
        "    def predict_prices(self, data):\n",
        "\n",
        "        data = np.array(data).reshape(-1, 1)\n",
        "\n",
        "        scaled_data = scaler.transform(data)\n",
        "        X = np.array([scaled_data[i-seq_length:i] for i in range(seq_length, len(scaled_data))])\n",
        "        X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "\n",
        "        if X.size > 0:\n",
        "            predicted = model.predict(X)\n",
        "            predicted = scaler.inverse_transform(predicted)\n",
        "\n",
        "            predicted_padded = np.zeros(len(data))\n",
        "            predicted_padded[seq_length:] = predicted.flatten()\n",
        "            predicted_padded[:seq_length] = data[:seq_length].flatten()\n",
        "\n",
        "\n",
        "            return predicted_padded\n",
        "        else:\n",
        "            return np.zeros(len(data))\n",
        "\n",
        "    def next(self):\n",
        "        if crossover(self.signal, self.data.Close):\n",
        "            self.buy()\n",
        "        elif crossover(self.data.Close, self.signal):\n",
        "            self.sell()\n",
        "\n",
        "\n",
        "data_for_backtest = yf.download(\"AAPL\", start=test_start_date, end=test_end_date)\n",
        "bt = Backtest(data_for_backtest, LSTMForecastStrategy, cash=10000, commission=.002)\n",
        "stats = bt.run()\n",
        "bt.plot()\n",
        "print(stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsJsPm0xCVpY",
        "outputId": "0511f25f-9c07-4695-8e12-7bd91feb00ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 01m 24s]\n",
            "val_loss: 0.003505009226500988\n",
            "\n",
            "Best val_loss So Far: 0.003505009226500988\n",
            "Total elapsed time: 00h 03m 01s\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "200               |100               |units\n",
            "0.4               |0.2               |dropout\n",
            "2                 |2                 |num_layers\n",
            "150               |100               |units_0\n",
            "0.2               |0.2               |dropout_0\n",
            "100               |150               |units_last\n",
            "0.4               |0.4               |dropout_last\n",
            "0.001             |0.0001            |learning_rate\n",
            "50                |200               |units_1\n",
            "0.3               |0.2               |dropout_1\n",
            "100               |100               |units_2\n",
            "0.4               |0.4               |dropout_2\n",
            "150               |50                |units_3\n",
            "0.3               |0.2               |dropout_3\n",
            "\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 12s 719ms/step - loss: 0.2584 - val_loss: 0.0071\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 0.0627 - val_loss: 0.1254\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 2s 327ms/step - loss: 0.0316 - val_loss: 0.0030\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 2s 305ms/step - loss: 0.0314 - val_loss: 0.0479\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 2s 358ms/step - loss: 0.0271 - val_loss: 0.0528\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 3s 571ms/step - loss: 0.0178 - val_loss: 0.0085\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 2s 461ms/step - loss: 0.0202 - val_loss: 0.0229\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.0197 - val_loss: 0.0402\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 1s 297ms/step - loss: 0.0177 - val_loss: 0.0113\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 2s 311ms/step - loss: 0.0164 - val_loss: 0.0274\n"
          ]
        }
      ]
    }
  ]
}